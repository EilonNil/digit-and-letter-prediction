# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1usVjoblNNX5k3Zh2DQW7GXmpXNULHtV_

תיאור הפרוייקט: מכונה שמצליחה לזהות ספרות ואותיות באנגלית.
שאלת המחקר: האם מכונה יכולה להבדיל בין ספרות ואותיות באנגלית.
איסוף הנתונים: לקחתי דטאסט מקאגל של 110000 תמונות מתויגות של ספרות ואותיות באנגלית.
קישור לנתונים: https://www.kaggle.com/crawford/emnist?select=emnist-balanced-train.csv

קריאה והצגת הנתונים
"""

import pandas as pd #עם זה נוכל לקרוא את הקובץ 
df = pd.read_csv('/content/drive/MyDrive/data/csv/emnist-balanced-train.csv', header=None)
df.shape

"""מכיוון שיש לי 110000 תמונות אני לא צריך לבצע augmentation על התמונות"""

df.head()

#הדטאסט הוא דסאסט של תמונות ולכן אם לא חסר תיוג לאף תמונה לא חסרים ערכים אחרים
df.isnull().sum().head(10)

df[0].unique()

"""הצגת דגם של אחד התמונות.
התמונות בדטאסט הם על הצד.
בשורה 15 האות המוצגת היא האות C
"""

from PIL import Image 
import matplotlib.pyplot as plt #בעזרת אלה נוכל להציג את התמונה
i = int(input("please enter a row number"))
wtf = df.iloc[i, 1:]
wtf.shape
wtf = wtf.values.reshape(28,28)
plt.imshow(wtf, cmap='gray')

"""חילוק הנתונים לX וY"""

X = df.iloc[:, 1:].values #X = rgbs
Y = df.iloc[:, 0].values #Y = label

"""נרמול ערכי הRGB"""

X = X/255 #ינרמל את ערכי הrgb

"""חיזוי"""

from sklearn.model_selection import train_test_split #בעזרת זה נוכל לחלק את הדטאסט ללמידה ולמבחן
from sklearn import svm #שיטת לימוד svm
from sklearn.svm import SVC #שיטת חיזוי SVC

#חלוקה לtrain וtest
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)

clf = svm.SVC(kernel='linear', C=25, gamma = 0.001) # Linear Kernel ## ('linear', 'poly', 'rbf')

#אימון המודל
clf.fit(X_train, y_train)

#חיזוי והצגת הדיוק
y_pred = clf.predict(X_test)
clf.score(X_test, y_test)

"""rbf gamma = 0
 c = 1: 0.84
 c = 5: 0.856
 c = 10: 0.853
 c = 15: 0.851
 c = 25: 0.85

 rbf gamma = 0.01
 c = 1: 0.837
 c = 5: 0.854
 c = 20: 0.852
 c = 15: 0.8507
 c = 25: 0.849

 אנחנו רואים ש
 c = 5 gamma = 0
 נותן את התוצאות המדויקות ביותר
"""

#most accurate prediction
clf = svm.SVC(kernel='rbf', C=5) # rbf Kernel ## ('linear', 'poly', 'rbf')

#אימון המודל
clf.fit(X_train, y_train)

#חיזוי והצגת הדיוק
y_pred = clf.predict(X_test)
print(clf.score(X_test, y_test))

clf = svm.SVC(kernel='poly', C=5) # poly Kernel ## ('linear', 'poly', 'rbf')

#אימון המודל
clf.fit(X_train, y_train)

#חיזוי והצגת הדיוק
y_pred = clf.predict(X_test)
clf.score(X_test, y_test)

#חיזוי בעזרת knn
from sklearn.neighbors import KNeighborsClassifier #שיטת חיזוי knn 
knn1 = KNeighborsClassifier(n_neighbors = 3)  
knn1.fit(X_train,y_train)     
print("k = {} score test: {}".format(3,knn1.score(X_test, y_test)))

#חיזוי בעזרת knn
from sklearn.neighbors import KNeighborsClassifier #שיטת חיזוי knn
for k in range(4,50,1):
    knn1 = KNeighborsClassifier(n_neighbors = k)  
    knn1.fit(X_train,y_train)     
    print("k = {} score test: {}".format(k,knn1.score(X_test, y_test)))
    print('')

"""אנחנו יכולים לראות שהחיזוי הכי מוצלח היה של שיטת הsvm עם הקרנל rbf ועם c = 5 gamma = 0"""

from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix #בעזרת זה נוכל להצגיד confusion matrix של החיזוי

#הצגת confusion matrix של החיזוי הכי מוצלח
confusion_matrix(y_test,y_pred)

plot_confusion_matrix(clf, X_test, y_test,values_format="d",cmap='Blues'); #הצגת תמונה של הconfusion matrix

#מבחן דוח סיווג
print(classification_report(y_test,y_pred,digits=4))